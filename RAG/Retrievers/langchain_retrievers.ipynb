{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"MY_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain chromadb faiss-cpu openai tiktoken langchain_openai langchain-community wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the retriever (optional: set language and top_k)\n",
    "retriever = WikipediaRetriever(top_k_results=2, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your query\n",
    "query = \"the geopolitical history of india and pakistan from the perspective of a chinese\"\n",
    "\n",
    "# Get relevant Wikipedia documents\n",
    "docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print retrieved content\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(f\"Content:\\n{doc.page_content}...\")  # truncate for display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embedding model\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 3: Create Chroma vector store in memory\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert vectorstore into a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Chroma used for?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 2: Create the FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MMR in the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                   # <-- This enables MMR\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.5}  # k = top results, lambda_mult = relevance-diversity balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is langchain?\"\n",
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiquery Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant health & wellness documents\n",
    "all_docs = [\n",
    "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
    "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
    "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
    "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
    "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
    "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
    "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
    "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
    "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
    "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(documents=all_docs, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrievers\n",
    "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"How to improve energy levels and maintain balance?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve results\n",
    "similarity_results = similarity_retriever.invoke(query)\n",
    "multiquery_results= multiquery_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(similarity_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "print(\"*\"*150)\n",
    "\n",
    "for i, doc in enumerate(multiquery_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the document objects from the previous data\n",
    "docs = [\n",
    "    Document(page_content=(\n",
    "        \"\"\"The Grand Canyon is one of the most visited natural wonders in the world.\n",
    "        Photosynthesis is the process by which green plants convert sunlight into energy.\n",
    "        Millions of tourists travel to see it every year. The rocks date back millions of years.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc1\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"In medieval Europe, castles were built primarily for defense.\n",
    "        The chlorophyll in plant cells captures sunlight during photosynthesis.\n",
    "        Knights wore armor made of metal. Siege weapons were often used to breach castle walls.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc2\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"Basketball was invented by Dr. James Naismith in the late 19th century.\n",
    "        It was originally played with a soccer ball and peach baskets. NBA is now a global league.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc3\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"The history of cinema began in the late 1800s. Silent films were the earliest form.\n",
    "        Thomas Edison was among the pioneers. Photosynthesis does not occur in animal cells.\n",
    "        Modern filmmaking involves complex CGI and sound design.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc4\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS vector store from the documents\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the compressor using an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the contextual compression retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the retriever\n",
    "query = \"What is photosynthesis?\"\n",
    "compressed_results = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(compressed_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
